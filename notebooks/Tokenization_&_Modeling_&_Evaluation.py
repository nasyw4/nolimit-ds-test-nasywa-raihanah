# -*- coding: utf-8 -*-
"""Copy of Tokenization & Modeling & Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cxqQ_iG7_PL1892oVP4Fh4nwfYCpaHWY

## Library
"""

!pip install transformers datasets accelerate

!pip install evaluate

import pandas as pd
import numpy as np
import evaluate
from sklearn.model_selection import train_test_split
from datasets import Dataset, DatasetDict
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    Pipeline,
    DataCollatorWithPadding
)

from google.colab import drive
drive.mount('/content/drive')

"""## Train Test Split"""

df = pd.read_csv("/content/drive/MyDrive/Dataset Review Produk/clean_reviews.csv")
df.head()

df_model = df[['clean_text', 'sentiment']]
df_model.head()

train_df, test_df = train_test_split(
    df_model,
    test_size=0.2,
    stratify=df["sentiment"],
    random_state=42
)

train_df = train_df.sample(500, random_state=42)
test_df = test_df.sample(500, random_state=42)

print("Train size:", train_df.shape)
print("Test size:", test_df.shape)

print(train_df["sentiment"].value_counts(normalize=True))
print(test_df["sentiment"].value_counts(normalize=True))

train_df.to_csv("/content/drive/MyDrive/Dataset Review Produk/train_reviews_500.csv", index=False)
test_df.to_csv("/content/drive/MyDrive/Dataset Review Produk/test_reviews_500.csv", index=False)

"""## Tokenzation"""

train_df = pd.read_csv("/content/drive/MyDrive/Dataset Review Produk/train_reviews_500.csv")
test_df = pd.read_csv("/content/drive/MyDrive/Dataset Review Produk/test_reviews_500.csv")

model_name = "w11wo/indonesian-roberta-base-sentiment-classifier"
tokenizer = AutoTokenizer.from_pretrained(model_name)

label2id = {"negative": 0, "neutral": 1, "positive": 2}
id2label = {0: "negative", 1: "neutral", 2: "positive"}

train_df["label"] = train_df["sentiment"].map(label2id)
test_df["label"] = test_df["sentiment"].map(label2id)

train_dataset = Dataset.from_pandas(train_df[['clean_text', 'label']])
test_dataset = Dataset.from_pandas(test_df[['clean_text', 'label']])

dataset = DatasetDict({
    "train": train_dataset,
    "test": test_dataset
})

def tokenize_function(example):
  return tokenizer(
      example["clean_text"],
      truncation=True,
      padding="max_length",
      max_length=64
  )

tokenize_dataset = dataset.map(tokenize_function, batched=True, remove_columns=["clean_text"]
)

tokenize_dataset["train"][0]

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

"""## Modeling"""

import evaluate

accuray_metric = evaluate.load("accuracy")
f1_metric = evaluate.load("f1")

def compute_metrics(eval_pred):
  logits, labels = eval_pred
  predictions = np.argmax(logits, axis=-1)

  acc = accuray_metric.compute(predictions=predictions, references=labels)
  f1 = f1_metric.compute(predictions=predictions, references=labels, average="weighted")

  return {
      "accuracy": acc["accuracy"],
      "f1": f1["f1"]
  }

import transformers
print(transformers.__version__)
# seharusnya >= 4.5.0 (lebih baik >= 4.20+)

training_args = TrainingArguments(
    output_dir="/content/drive/MyDrive/Dataset Review Produk/model_output",

    eval_strategy="epoch",
    save_strategy="epoch",

    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,

    load_best_model_at_end=True,
    metric_for_best_model="f1",
)

tokenize_dataset["train"].column_names

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=len(label2id),
    id2label=id2label,
    label2id=label2id
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenize_dataset["train"],
    eval_dataset=tokenize_dataset["test"],
    processing_class=tokenizer, # Changed from tokenizer=tokenizer
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

# Train Model
trainer.train()

# Evaluate
results = trainer.evaluate()
results

trainer.save_model("/content/drive/MyDrive/Dataset Review Produk/sentiment_model")
tokenizer.save_pretrained("/content/drive/MyDrive/Dataset Review Produk/sentiment_model")

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

text = "Pengiriman lambat, barangnya lumayan!"
inputs = tokenizer(text, return_tensors="pt")

with torch.no_grad():
    logits = model(**inputs).logits

pred = torch.argmax(logits).item()
id2label[pred]

"""## Test"""

def predict_sentiment(text, model, tokenizer, id2label):
    # Tokenisasi input
    inputs = tokenizer(text, return_tensors="pt")

    # Non-training mode
    with torch.no_grad():
        logits = model(**inputs).logits

    # Ambil label dengan skor tertinggi
    pred_id = torch.argmax(logits, dim=1).item()
    return id2label[pred_id]


while True:
    user_input = input("Masukkan review (atau ketik 'exit' untuk keluar): ")

    if user_input.lower() == "exit":
        print("Program selesai.")
        break

    sentiment = predict_sentiment(user_input, model, tokenizer, id2label)
    print(f"Prediksi Sentiment: {sentiment}\n")